Text2AC-Zero: Consistent Synthesis of Animated Characters using 2D Diffusion
MotionCrafter: One-Shot Motion Customization of Diffusion Models
Photorealistic Video Generation with Diffusion Models
Customizing Motion in Text-to-Video Diffusion Models
DreaMoving: A Human Dance Video Generation Framework based on Diffusion Models
DreamVideo: Composing Your Dream Videos with Customized Subject and Motion
GenTron: Delving Deep into Diffusion Transformers for Image and Video Generation
AnimateZero: Video Diffusion Models are Zero-Shot Image Animators
F3-Pruning: A Training-Free and Generalized Pruning Strategy towards Faster and Finer Text-to-Video Synthesis
DreamVideo: High-Fidelity Image-to-Video Generation with Image Retention and Text Guidance
Decouple Content and Motion for Conditional Image-to-Video Generation
GPT4Motion: Scripting Physical Motions in Text-to-Video Generation via Blender-Oriented GPT Planning
MoVideo: Motion-Aware Video Generation with Diffusion Models
BIVDiff: A Training-Free Framework for General-Purpose Video Synthesis via Bridging Image and Video Diffusion Models
LivePhoto: Real Image Animation with Text-guided Motion Control
VMC: Video Motion Customization using Temporal Attention Adaption for Text-to-Video Diffusion Models
SparseCtrl: Adding Sparse Controls to Text-to-Video Diffusion Models
MagicAnimate: Temporally Consistent Human Image Animation using Diffusion Model
Sketch Video Synthesis
Breathing Life Into Sketches Using Text-to-Video Priors
Animate124: Animating One Image to 4D Dynamic Scene
Fine-Grained Open Domain Image Animation with Motion Guidance
MagicDance: Realistic Human Dance Video Generation with Motions & Facial Expressions Transfer
Make Pixels Dance: High-Dynamic Video Generation
Emu Video: Factorizing Text-to-Video Generation by Explicit Image Conditioning
FastBlend: a Powerful Model-Free Toolkit Making Video Stylization Easier
I2VGen-XL: High-Quality Image-to-Video Synthesis via Cascaded Diffusion Models
DiffDub: Person-generic Visual Dubbing Using Inpainting Renderer with Diffusion Auto-encoder
VideoDreamer: Customized Multi-Subject Text-to-Video Generation with Disen-Mix Finetuning
LatentWarp: Consistent Diffusion Latents for Zero-Shot Video-to-Video Translation
SEINE: Short-to-Long Video Diffusion Model for Generative Transition and Prediction
One Style is All you Need to Generate a Video
FreeNoise: Tuning-Free Longer Video Diffusion Via Noise Rescheduling
LAMP: Learn A Motion Pattern for Few-Shot-Based Video Generation
ConditionVideo: Training-Free Condition-Guided Text-to-Video Generation
MotionDirector: Motion Customization of Text-to-Video Diffusion Models
AnimateDiff: Animate Your Personalized Text-to-Image Diffusion Models  without Specific Tuning
